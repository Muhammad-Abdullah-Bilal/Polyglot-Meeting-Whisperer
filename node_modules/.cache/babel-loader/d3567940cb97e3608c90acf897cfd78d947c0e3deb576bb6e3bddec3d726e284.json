{"ast":null,"code":"var _s = $RefreshSig$();\n// import { useState, useRef, useEffect } from 'react';\n\n// const useAudioRecording = () => {\n//   const [isRecording, setIsRecording] = useState(false);\n//   const [isLoading, setIsLoading] = useState(false);\n//   const audioContextRef = useRef(null);\n//   const mediaRecorderRef = useRef(null);\n//   const audioChunksRef = useRef([]);\n\n//   useEffect(() => {\n//     if (isRecording && !audioContextRef.current) {\n//       initializeAudio();\n//     } else if (!isRecording && audioContextRef.current) {\n//       stopRecording();\n//     }\n//   }, [isRecording]);\n\n//   const initializeAudio = async () => {\n//     try {\n//       const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\n//       mediaRecorderRef.current = new MediaRecorder(stream);\n//       mediaRecorderRef.current.ondataavailable = (event) => audioChunksRef.current.push(event.data);\n//       mediaRecorderRef.current.onstop = processAudio;\n//       mediaRecorderRef.current.start();\n//     } catch (error) {\n//       console.error('Error accessing microphone:', error);\n//       simulateTranscription();\n//     }\n//   };\n\n//   const stopRecording = () => {\n//     if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\n//       mediaRecorderRef.current.stop();\n//     }\n//     if (audioContextRef.current) {\n//       audioContextRef.current.close();\n//       audioContextRef.current = null;\n//     }\n//   };\n\n//   const processAudio = () => {\n//     setIsLoading(true);\n//     const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\n\n//     // Simulate audio processing\n//     setTimeout(() => {\n//       const fakeData = [\n//         { \n//           speaker: 'Speaker 1', \n//           time: new Date().toLocaleTimeString(), \n//           text: 'Meeting in progress...' \n//         }\n//       ];\n\n//       setIsLoading(false);\n//       audioChunksRef.current = [];\n\n//       // Return processed data\n//       return fakeData;\n//     }, 1000);\n//   };\n\n//   const simulateTranscription = () => {\n//     setIsLoading(true);\n//     setTimeout(() => {\n//       const fakeData = [\n//         { speaker: 'Speaker 1', time: '09:00:12', text: 'Welcome to our quarterly review meeting.' },\n//         { speaker: 'Speaker 2', time: '09:00:45', text: 'Thank you for joining us today.' },\n//         { speaker: 'Speaker 3', time: '09:01:22', text: 'The results look very promising.' },\n//       ];\n//       setIsLoading(false);\n//       // This would normally be handled by a callback\n//     }, 1000);\n//   };\n\n//   const toggleRecording = () => {\n//     setIsRecording(prev => !prev);\n//   };\n\n//   return {\n//     isRecording,\n//     isLoading,\n//     toggleRecording,\n//     simulateTranscription\n//   };\n// };\n\n// export default useAudioRecording;\n\nimport { useState, useRef, useCallback } from 'react';\nconst useAudioRecording = () => {\n  _s();\n  const [isRecording, setIsRecording] = useState(false);\n  const [isLoading, setIsLoading] = useState(false);\n  const [error, setError] = useState(null);\n  const mediaRecorderRef = useRef(null);\n  const audioChunksRef = useRef([]);\n  const streamRef = useRef(null);\n  const startRecording = useCallback(async () => {\n    try {\n      setError(null);\n      setIsLoading(true);\n\n      // Request microphone access\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          echoCancellation: true,\n          noiseSuppression: true,\n          sampleRate: 44100\n        }\n      });\n      streamRef.current = stream;\n\n      // Create MediaRecorder\n      const mediaRecorder = new MediaRecorder(stream, {\n        mimeType: 'audio/webm;codecs=opus'\n      });\n      mediaRecorderRef.current = mediaRecorder;\n      audioChunksRef.current = [];\n\n      // Set up event handlers\n      mediaRecorder.ondataavailable = event => {\n        if (event.data.size > 0) {\n          audioChunksRef.current.push(event.data);\n        }\n      };\n      mediaRecorder.onstop = () => {\n        processAudioData();\n      };\n      mediaRecorder.onerror = event => {\n        console.error('MediaRecorder error:', event.error);\n        setError('Recording failed: ' + event.error);\n        setIsRecording(false);\n        setIsLoading(false);\n      };\n\n      // Start recording\n      mediaRecorder.start(100); // Collect data every 100ms\n      setIsRecording(true);\n      setIsLoading(false);\n      console.log('Recording started successfully');\n    } catch (err) {\n      console.error('Error starting recording:', err);\n      setError('Could not access microphone: ' + err.message);\n      setIsRecording(false);\n      setIsLoading(false);\n    }\n  }, []);\n  const stopRecording = useCallback(() => {\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\n      setIsLoading(true);\n      mediaRecorderRef.current.stop();\n      setIsRecording(false);\n\n      // Stop all tracks\n      if (streamRef.current) {\n        streamRef.current.getTracks().forEach(track => track.stop());\n        streamRef.current = null;\n      }\n      console.log('Recording stopped');\n    }\n  }, []);\n  const processAudioData = useCallback(() => {\n    if (audioChunksRef.current.length > 0) {\n      const audioBlob = new Blob(audioChunksRef.current, {\n        type: 'audio/webm'\n      });\n      console.log('Audio blob created:', audioBlob.size, 'bytes');\n\n      // Here you would typically send the audio to a transcription service\n      // For now, we'll just simulate processing\n      setTimeout(() => {\n        setIsLoading(false);\n        console.log('Audio processing completed');\n      }, 1000);\n\n      // Clear the chunks\n      audioChunksRef.current = [];\n    } else {\n      setIsLoading(false);\n    }\n  }, []);\n  const resetRecording = useCallback(() => {\n    if (isRecording) {\n      stopRecording();\n    }\n    audioChunksRef.current = [];\n    setError(null);\n    setIsLoading(false);\n    console.log('Recording reset');\n  }, [isRecording, stopRecording]);\n  return {\n    isRecording,\n    isLoading,\n    error,\n    startRecording,\n    stopRecording,\n    resetRecording\n  };\n};\n_s(useAudioRecording, \"hRD7VkqW8SWwF/aodbgQ+n23TbM=\");\nexport default useAudioRecording;","map":{"version":3,"names":["useState","useRef","useCallback","useAudioRecording","_s","isRecording","setIsRecording","isLoading","setIsLoading","error","setError","mediaRecorderRef","audioChunksRef","streamRef","startRecording","stream","navigator","mediaDevices","getUserMedia","audio","echoCancellation","noiseSuppression","sampleRate","current","mediaRecorder","MediaRecorder","mimeType","ondataavailable","event","data","size","push","onstop","processAudioData","onerror","console","start","log","err","message","stopRecording","state","stop","getTracks","forEach","track","length","audioBlob","Blob","type","setTimeout","resetRecording"],"sources":["C:/Downloads/Downloads/Polyglot-Meeting-Whisperer/src/hooks/useAudioRecording.js"],"sourcesContent":["// import { useState, useRef, useEffect } from 'react';\r\n\r\n// const useAudioRecording = () => {\r\n//   const [isRecording, setIsRecording] = useState(false);\r\n//   const [isLoading, setIsLoading] = useState(false);\r\n//   const audioContextRef = useRef(null);\r\n//   const mediaRecorderRef = useRef(null);\r\n//   const audioChunksRef = useRef([]);\r\n\r\n//   useEffect(() => {\r\n//     if (isRecording && !audioContextRef.current) {\r\n//       initializeAudio();\r\n//     } else if (!isRecording && audioContextRef.current) {\r\n//       stopRecording();\r\n//     }\r\n//   }, [isRecording]);\r\n\r\n//   const initializeAudio = async () => {\r\n//     try {\r\n//       const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n//       const source = audioContextRef.current.createMediaStreamSource(stream);\r\n//       mediaRecorderRef.current = new MediaRecorder(stream);\r\n//       mediaRecorderRef.current.ondataavailable = (event) => audioChunksRef.current.push(event.data);\r\n//       mediaRecorderRef.current.onstop = processAudio;\r\n//       mediaRecorderRef.current.start();\r\n//     } catch (error) {\r\n//       console.error('Error accessing microphone:', error);\r\n//       simulateTranscription();\r\n//     }\r\n//   };\r\n\r\n//   const stopRecording = () => {\r\n//     if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\r\n//       mediaRecorderRef.current.stop();\r\n//     }\r\n//     if (audioContextRef.current) {\r\n//       audioContextRef.current.close();\r\n//       audioContextRef.current = null;\r\n//     }\r\n//   };\r\n\r\n//   const processAudio = () => {\r\n//     setIsLoading(true);\r\n//     const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\r\n    \r\n//     // Simulate audio processing\r\n//     setTimeout(() => {\r\n//       const fakeData = [\r\n//         { \r\n//           speaker: 'Speaker 1', \r\n//           time: new Date().toLocaleTimeString(), \r\n//           text: 'Meeting in progress...' \r\n//         }\r\n//       ];\r\n      \r\n//       setIsLoading(false);\r\n//       audioChunksRef.current = [];\r\n      \r\n//       // Return processed data\r\n//       return fakeData;\r\n//     }, 1000);\r\n//   };\r\n\r\n//   const simulateTranscription = () => {\r\n//     setIsLoading(true);\r\n//     setTimeout(() => {\r\n//       const fakeData = [\r\n//         { speaker: 'Speaker 1', time: '09:00:12', text: 'Welcome to our quarterly review meeting.' },\r\n//         { speaker: 'Speaker 2', time: '09:00:45', text: 'Thank you for joining us today.' },\r\n//         { speaker: 'Speaker 3', time: '09:01:22', text: 'The results look very promising.' },\r\n//       ];\r\n//       setIsLoading(false);\r\n//       // This would normally be handled by a callback\r\n//     }, 1000);\r\n//   };\r\n\r\n//   const toggleRecording = () => {\r\n//     setIsRecording(prev => !prev);\r\n//   };\r\n\r\n//   return {\r\n//     isRecording,\r\n//     isLoading,\r\n//     toggleRecording,\r\n//     simulateTranscription\r\n//   };\r\n// };\r\n\r\n// export default useAudioRecording;\r\n\r\n\r\n\r\n\r\n\r\n\r\nimport { useState, useRef, useCallback } from 'react';\r\n\r\nconst useAudioRecording = () => {\r\n  const [isRecording, setIsRecording] = useState(false);\r\n  const [isLoading, setIsLoading] = useState(false);\r\n  const [error, setError] = useState(null);\r\n  \r\n  const mediaRecorderRef = useRef(null);\r\n  const audioChunksRef = useRef([]);\r\n  const streamRef = useRef(null);\r\n\r\n  const startRecording = useCallback(async () => {\r\n    try {\r\n      setError(null);\r\n      setIsLoading(true);\r\n      \r\n      // Request microphone access\r\n      const stream = await navigator.mediaDevices.getUserMedia({ \r\n        audio: {\r\n          echoCancellation: true,\r\n          noiseSuppression: true,\r\n          sampleRate: 44100,\r\n        }\r\n      });\r\n      \r\n      streamRef.current = stream;\r\n      \r\n      // Create MediaRecorder\r\n      const mediaRecorder = new MediaRecorder(stream, {\r\n        mimeType: 'audio/webm;codecs=opus'\r\n      });\r\n      \r\n      mediaRecorderRef.current = mediaRecorder;\r\n      audioChunksRef.current = [];\r\n      \r\n      // Set up event handlers\r\n      mediaRecorder.ondataavailable = (event) => {\r\n        if (event.data.size > 0) {\r\n          audioChunksRef.current.push(event.data);\r\n        }\r\n      };\r\n      \r\n      mediaRecorder.onstop = () => {\r\n        processAudioData();\r\n      };\r\n      \r\n      mediaRecorder.onerror = (event) => {\r\n        console.error('MediaRecorder error:', event.error);\r\n        setError('Recording failed: ' + event.error);\r\n        setIsRecording(false);\r\n        setIsLoading(false);\r\n      };\r\n      \r\n      // Start recording\r\n      mediaRecorder.start(100); // Collect data every 100ms\r\n      setIsRecording(true);\r\n      setIsLoading(false);\r\n      \r\n      console.log('Recording started successfully');\r\n      \r\n    } catch (err) {\r\n      console.error('Error starting recording:', err);\r\n      setError('Could not access microphone: ' + err.message);\r\n      setIsRecording(false);\r\n      setIsLoading(false);\r\n    }\r\n  }, []);\r\n\r\n  const stopRecording = useCallback(() => {\r\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\r\n      setIsLoading(true);\r\n      mediaRecorderRef.current.stop();\r\n      setIsRecording(false);\r\n      \r\n      // Stop all tracks\r\n      if (streamRef.current) {\r\n        streamRef.current.getTracks().forEach(track => track.stop());\r\n        streamRef.current = null;\r\n      }\r\n      \r\n      console.log('Recording stopped');\r\n    }\r\n  }, []);\r\n\r\n  const processAudioData = useCallback(() => {\r\n    if (audioChunksRef.current.length > 0) {\r\n      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });\r\n      \r\n      console.log('Audio blob created:', audioBlob.size, 'bytes');\r\n      \r\n      // Here you would typically send the audio to a transcription service\r\n      // For now, we'll just simulate processing\r\n      setTimeout(() => {\r\n        setIsLoading(false);\r\n        console.log('Audio processing completed');\r\n      }, 1000);\r\n      \r\n      // Clear the chunks\r\n      audioChunksRef.current = [];\r\n    } else {\r\n      setIsLoading(false);\r\n    }\r\n  }, []);\r\n\r\n  const resetRecording = useCallback(() => {\r\n    if (isRecording) {\r\n      stopRecording();\r\n    }\r\n    \r\n    audioChunksRef.current = [];\r\n    setError(null);\r\n    setIsLoading(false);\r\n    \r\n    console.log('Recording reset');\r\n  }, [isRecording, stopRecording]);\r\n\r\n  return {\r\n    isRecording,\r\n    isLoading,\r\n    error,\r\n    startRecording,\r\n    stopRecording,\r\n    resetRecording\r\n  };\r\n};\r\n\r\nexport default useAudioRecording;"],"mappings":";AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAOA,SAASA,QAAQ,EAAEC,MAAM,EAAEC,WAAW,QAAQ,OAAO;AAErD,MAAMC,iBAAiB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC9B,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGN,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACO,SAAS,EAAEC,YAAY,CAAC,GAAGR,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACS,KAAK,EAAEC,QAAQ,CAAC,GAAGV,QAAQ,CAAC,IAAI,CAAC;EAExC,MAAMW,gBAAgB,GAAGV,MAAM,CAAC,IAAI,CAAC;EACrC,MAAMW,cAAc,GAAGX,MAAM,CAAC,EAAE,CAAC;EACjC,MAAMY,SAAS,GAAGZ,MAAM,CAAC,IAAI,CAAC;EAE9B,MAAMa,cAAc,GAAGZ,WAAW,CAAC,YAAY;IAC7C,IAAI;MACFQ,QAAQ,CAAC,IAAI,CAAC;MACdF,YAAY,CAAC,IAAI,CAAC;;MAElB;MACA,MAAMO,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QACvDC,KAAK,EAAE;UACLC,gBAAgB,EAAE,IAAI;UACtBC,gBAAgB,EAAE,IAAI;UACtBC,UAAU,EAAE;QACd;MACF,CAAC,CAAC;MAEFT,SAAS,CAACU,OAAO,GAAGR,MAAM;;MAE1B;MACA,MAAMS,aAAa,GAAG,IAAIC,aAAa,CAACV,MAAM,EAAE;QAC9CW,QAAQ,EAAE;MACZ,CAAC,CAAC;MAEFf,gBAAgB,CAACY,OAAO,GAAGC,aAAa;MACxCZ,cAAc,CAACW,OAAO,GAAG,EAAE;;MAE3B;MACAC,aAAa,CAACG,eAAe,GAAIC,KAAK,IAAK;QACzC,IAAIA,KAAK,CAACC,IAAI,CAACC,IAAI,GAAG,CAAC,EAAE;UACvBlB,cAAc,CAACW,OAAO,CAACQ,IAAI,CAACH,KAAK,CAACC,IAAI,CAAC;QACzC;MACF,CAAC;MAEDL,aAAa,CAACQ,MAAM,GAAG,MAAM;QAC3BC,gBAAgB,CAAC,CAAC;MACpB,CAAC;MAEDT,aAAa,CAACU,OAAO,GAAIN,KAAK,IAAK;QACjCO,OAAO,CAAC1B,KAAK,CAAC,sBAAsB,EAAEmB,KAAK,CAACnB,KAAK,CAAC;QAClDC,QAAQ,CAAC,oBAAoB,GAAGkB,KAAK,CAACnB,KAAK,CAAC;QAC5CH,cAAc,CAAC,KAAK,CAAC;QACrBE,YAAY,CAAC,KAAK,CAAC;MACrB,CAAC;;MAED;MACAgB,aAAa,CAACY,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;MAC1B9B,cAAc,CAAC,IAAI,CAAC;MACpBE,YAAY,CAAC,KAAK,CAAC;MAEnB2B,OAAO,CAACE,GAAG,CAAC,gCAAgC,CAAC;IAE/C,CAAC,CAAC,OAAOC,GAAG,EAAE;MACZH,OAAO,CAAC1B,KAAK,CAAC,2BAA2B,EAAE6B,GAAG,CAAC;MAC/C5B,QAAQ,CAAC,+BAA+B,GAAG4B,GAAG,CAACC,OAAO,CAAC;MACvDjC,cAAc,CAAC,KAAK,CAAC;MACrBE,YAAY,CAAC,KAAK,CAAC;IACrB;EACF,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMgC,aAAa,GAAGtC,WAAW,CAAC,MAAM;IACtC,IAAIS,gBAAgB,CAACY,OAAO,IAAIZ,gBAAgB,CAACY,OAAO,CAACkB,KAAK,KAAK,UAAU,EAAE;MAC7EjC,YAAY,CAAC,IAAI,CAAC;MAClBG,gBAAgB,CAACY,OAAO,CAACmB,IAAI,CAAC,CAAC;MAC/BpC,cAAc,CAAC,KAAK,CAAC;;MAErB;MACA,IAAIO,SAAS,CAACU,OAAO,EAAE;QACrBV,SAAS,CAACU,OAAO,CAACoB,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACH,IAAI,CAAC,CAAC,CAAC;QAC5D7B,SAAS,CAACU,OAAO,GAAG,IAAI;MAC1B;MAEAY,OAAO,CAACE,GAAG,CAAC,mBAAmB,CAAC;IAClC;EACF,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMJ,gBAAgB,GAAG/B,WAAW,CAAC,MAAM;IACzC,IAAIU,cAAc,CAACW,OAAO,CAACuB,MAAM,GAAG,CAAC,EAAE;MACrC,MAAMC,SAAS,GAAG,IAAIC,IAAI,CAACpC,cAAc,CAACW,OAAO,EAAE;QAAE0B,IAAI,EAAE;MAAa,CAAC,CAAC;MAE1Ed,OAAO,CAACE,GAAG,CAAC,qBAAqB,EAAEU,SAAS,CAACjB,IAAI,EAAE,OAAO,CAAC;;MAE3D;MACA;MACAoB,UAAU,CAAC,MAAM;QACf1C,YAAY,CAAC,KAAK,CAAC;QACnB2B,OAAO,CAACE,GAAG,CAAC,4BAA4B,CAAC;MAC3C,CAAC,EAAE,IAAI,CAAC;;MAER;MACAzB,cAAc,CAACW,OAAO,GAAG,EAAE;IAC7B,CAAC,MAAM;MACLf,YAAY,CAAC,KAAK,CAAC;IACrB;EACF,CAAC,EAAE,EAAE,CAAC;EAEN,MAAM2C,cAAc,GAAGjD,WAAW,CAAC,MAAM;IACvC,IAAIG,WAAW,EAAE;MACfmC,aAAa,CAAC,CAAC;IACjB;IAEA5B,cAAc,CAACW,OAAO,GAAG,EAAE;IAC3Bb,QAAQ,CAAC,IAAI,CAAC;IACdF,YAAY,CAAC,KAAK,CAAC;IAEnB2B,OAAO,CAACE,GAAG,CAAC,iBAAiB,CAAC;EAChC,CAAC,EAAE,CAAChC,WAAW,EAAEmC,aAAa,CAAC,CAAC;EAEhC,OAAO;IACLnC,WAAW;IACXE,SAAS;IACTE,KAAK;IACLK,cAAc;IACd0B,aAAa;IACbW;EACF,CAAC;AACH,CAAC;AAAC/C,EAAA,CA1HID,iBAAiB;AA4HvB,eAAeA,iBAAiB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}