{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useRef, useEffect } from 'react';\nconst useAudioRecording = () => {\n  _s();\n  const [isRecording, setIsRecording] = useState(false);\n  const [isLoading, setIsLoading] = useState(false);\n  const audioContextRef = useRef(null);\n  const mediaRecorderRef = useRef(null);\n  const audioChunksRef = useRef([]);\n  useEffect(() => {\n    if (isRecording && !audioContextRef.current) {\n      initializeAudio();\n    } else if (!isRecording && audioContextRef.current) {\n      stopRecording();\n    }\n  }, [isRecording]);\n  const initializeAudio = async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: true\n      });\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      const source = audioContextRef.current.createMediaStreamSource(stream);\n      mediaRecorderRef.current = new MediaRecorder(stream);\n      mediaRecorderRef.current.ondataavailable = event => audioChunksRef.current.push(event.data);\n      mediaRecorderRef.current.onstop = processAudio;\n      mediaRecorderRef.current.start();\n    } catch (error) {\n      console.error('Error accessing microphone:', error);\n      simulateTranscription();\n    }\n  };\n  const stopRecording = () => {\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\n      mediaRecorderRef.current.stop();\n    }\n    if (audioContextRef.current) {\n      audioContextRef.current.close();\n      audioContextRef.current = null;\n    }\n  };\n  const processAudio = () => {\n    setIsLoading(true);\n    const audioBlob = new Blob(audioChunksRef.current, {\n      type: 'audio/wav'\n    });\n\n    // Simulate audio processing\n    setTimeout(() => {\n      const fakeData = [{\n        speaker: 'Speaker 1',\n        time: new Date().toLocaleTimeString(),\n        text: 'Meeting in progress...'\n      }];\n      setIsLoading(false);\n      audioChunksRef.current = [];\n\n      // Return processed data\n      return fakeData;\n    }, 1000);\n  };\n  const simulateTranscription = () => {\n    setIsLoading(true);\n    setTimeout(() => {\n      const fakeData = [{\n        speaker: 'Speaker 1',\n        time: '09:00:12',\n        text: 'Welcome to our quarterly review meeting.'\n      }, {\n        speaker: 'Speaker 2',\n        time: '09:00:45',\n        text: 'Thank you for joining us today.'\n      }, {\n        speaker: 'Speaker 3',\n        time: '09:01:22',\n        text: 'The results look very promising.'\n      }];\n      setIsLoading(false);\n      // This would normally be handled by a callback\n    }, 1000);\n  };\n  const toggleRecording = () => {\n    setIsRecording(prev => !prev);\n  };\n  return {\n    isRecording,\n    isLoading,\n    toggleRecording,\n    simulateTranscription\n  };\n};\n_s(useAudioRecording, \"pflXYEzrNeqIRXrDwjHpd9Nlc1w=\");\nexport default useAudioRecording;","map":{"version":3,"names":["useState","useRef","useEffect","useAudioRecording","_s","isRecording","setIsRecording","isLoading","setIsLoading","audioContextRef","mediaRecorderRef","audioChunksRef","current","initializeAudio","stopRecording","stream","navigator","mediaDevices","getUserMedia","audio","window","AudioContext","webkitAudioContext","source","createMediaStreamSource","MediaRecorder","ondataavailable","event","push","data","onstop","processAudio","start","error","console","simulateTranscription","state","stop","close","audioBlob","Blob","type","setTimeout","fakeData","speaker","time","Date","toLocaleTimeString","text","toggleRecording","prev"],"sources":["C:/Downloads/Downloads/Polyglot-Meeting-Whisperer/src/hooks/useAudioRecording.js"],"sourcesContent":["import { useState, useRef, useEffect } from 'react';\r\n\r\nconst useAudioRecording = () => {\r\n  const [isRecording, setIsRecording] = useState(false);\r\n  const [isLoading, setIsLoading] = useState(false);\r\n  const audioContextRef = useRef(null);\r\n  const mediaRecorderRef = useRef(null);\r\n  const audioChunksRef = useRef([]);\r\n\r\n  useEffect(() => {\r\n    if (isRecording && !audioContextRef.current) {\r\n      initializeAudio();\r\n    } else if (!isRecording && audioContextRef.current) {\r\n      stopRecording();\r\n    }\r\n  }, [isRecording]);\r\n\r\n  const initializeAudio = async () => {\r\n    try {\r\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n      const source = audioContextRef.current.createMediaStreamSource(stream);\r\n      mediaRecorderRef.current = new MediaRecorder(stream);\r\n      mediaRecorderRef.current.ondataavailable = (event) => audioChunksRef.current.push(event.data);\r\n      mediaRecorderRef.current.onstop = processAudio;\r\n      mediaRecorderRef.current.start();\r\n    } catch (error) {\r\n      console.error('Error accessing microphone:', error);\r\n      simulateTranscription();\r\n    }\r\n  };\r\n\r\n  const stopRecording = () => {\r\n    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {\r\n      mediaRecorderRef.current.stop();\r\n    }\r\n    if (audioContextRef.current) {\r\n      audioContextRef.current.close();\r\n      audioContextRef.current = null;\r\n    }\r\n  };\r\n\r\n  const processAudio = () => {\r\n    setIsLoading(true);\r\n    const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\r\n    \r\n    // Simulate audio processing\r\n    setTimeout(() => {\r\n      const fakeData = [\r\n        { \r\n          speaker: 'Speaker 1', \r\n          time: new Date().toLocaleTimeString(), \r\n          text: 'Meeting in progress...' \r\n        }\r\n      ];\r\n      \r\n      setIsLoading(false);\r\n      audioChunksRef.current = [];\r\n      \r\n      // Return processed data\r\n      return fakeData;\r\n    }, 1000);\r\n  };\r\n\r\n  const simulateTranscription = () => {\r\n    setIsLoading(true);\r\n    setTimeout(() => {\r\n      const fakeData = [\r\n        { speaker: 'Speaker 1', time: '09:00:12', text: 'Welcome to our quarterly review meeting.' },\r\n        { speaker: 'Speaker 2', time: '09:00:45', text: 'Thank you for joining us today.' },\r\n        { speaker: 'Speaker 3', time: '09:01:22', text: 'The results look very promising.' },\r\n      ];\r\n      setIsLoading(false);\r\n      // This would normally be handled by a callback\r\n    }, 1000);\r\n  };\r\n\r\n  const toggleRecording = () => {\r\n    setIsRecording(prev => !prev);\r\n  };\r\n\r\n  return {\r\n    isRecording,\r\n    isLoading,\r\n    toggleRecording,\r\n    simulateTranscription\r\n  };\r\n};\r\n\r\nexport default useAudioRecording;"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAEnD,MAAMC,iBAAiB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC9B,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGN,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACO,SAAS,EAAEC,YAAY,CAAC,GAAGR,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAMS,eAAe,GAAGR,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMS,gBAAgB,GAAGT,MAAM,CAAC,IAAI,CAAC;EACrC,MAAMU,cAAc,GAAGV,MAAM,CAAC,EAAE,CAAC;EAEjCC,SAAS,CAAC,MAAM;IACd,IAAIG,WAAW,IAAI,CAACI,eAAe,CAACG,OAAO,EAAE;MAC3CC,eAAe,CAAC,CAAC;IACnB,CAAC,MAAM,IAAI,CAACR,WAAW,IAAII,eAAe,CAACG,OAAO,EAAE;MAClDE,aAAa,CAAC,CAAC;IACjB;EACF,CAAC,EAAE,CAACT,WAAW,CAAC,CAAC;EAEjB,MAAMQ,eAAe,GAAG,MAAAA,CAAA,KAAY;IAClC,IAAI;MACF,MAAME,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACzEV,eAAe,CAACG,OAAO,GAAG,KAAKQ,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;MAClF,MAAMC,MAAM,GAAGd,eAAe,CAACG,OAAO,CAACY,uBAAuB,CAACT,MAAM,CAAC;MACtEL,gBAAgB,CAACE,OAAO,GAAG,IAAIa,aAAa,CAACV,MAAM,CAAC;MACpDL,gBAAgB,CAACE,OAAO,CAACc,eAAe,GAAIC,KAAK,IAAKhB,cAAc,CAACC,OAAO,CAACgB,IAAI,CAACD,KAAK,CAACE,IAAI,CAAC;MAC7FnB,gBAAgB,CAACE,OAAO,CAACkB,MAAM,GAAGC,YAAY;MAC9CrB,gBAAgB,CAACE,OAAO,CAACoB,KAAK,CAAC,CAAC;IAClC,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;MACnDE,qBAAqB,CAAC,CAAC;IACzB;EACF,CAAC;EAED,MAAMrB,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIJ,gBAAgB,CAACE,OAAO,IAAIF,gBAAgB,CAACE,OAAO,CAACwB,KAAK,KAAK,UAAU,EAAE;MAC7E1B,gBAAgB,CAACE,OAAO,CAACyB,IAAI,CAAC,CAAC;IACjC;IACA,IAAI5B,eAAe,CAACG,OAAO,EAAE;MAC3BH,eAAe,CAACG,OAAO,CAAC0B,KAAK,CAAC,CAAC;MAC/B7B,eAAe,CAACG,OAAO,GAAG,IAAI;IAChC;EACF,CAAC;EAED,MAAMmB,YAAY,GAAGA,CAAA,KAAM;IACzBvB,YAAY,CAAC,IAAI,CAAC;IAClB,MAAM+B,SAAS,GAAG,IAAIC,IAAI,CAAC7B,cAAc,CAACC,OAAO,EAAE;MAAE6B,IAAI,EAAE;IAAY,CAAC,CAAC;;IAEzE;IACAC,UAAU,CAAC,MAAM;MACf,MAAMC,QAAQ,GAAG,CACf;QACEC,OAAO,EAAE,WAAW;QACpBC,IAAI,EAAE,IAAIC,IAAI,CAAC,CAAC,CAACC,kBAAkB,CAAC,CAAC;QACrCC,IAAI,EAAE;MACR,CAAC,CACF;MAEDxC,YAAY,CAAC,KAAK,CAAC;MACnBG,cAAc,CAACC,OAAO,GAAG,EAAE;;MAE3B;MACA,OAAO+B,QAAQ;IACjB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC;EAED,MAAMR,qBAAqB,GAAGA,CAAA,KAAM;IAClC3B,YAAY,CAAC,IAAI,CAAC;IAClBkC,UAAU,CAAC,MAAM;MACf,MAAMC,QAAQ,GAAG,CACf;QAAEC,OAAO,EAAE,WAAW;QAAEC,IAAI,EAAE,UAAU;QAAEG,IAAI,EAAE;MAA2C,CAAC,EAC5F;QAAEJ,OAAO,EAAE,WAAW;QAAEC,IAAI,EAAE,UAAU;QAAEG,IAAI,EAAE;MAAkC,CAAC,EACnF;QAAEJ,OAAO,EAAE,WAAW;QAAEC,IAAI,EAAE,UAAU;QAAEG,IAAI,EAAE;MAAmC,CAAC,CACrF;MACDxC,YAAY,CAAC,KAAK,CAAC;MACnB;IACF,CAAC,EAAE,IAAI,CAAC;EACV,CAAC;EAED,MAAMyC,eAAe,GAAGA,CAAA,KAAM;IAC5B3C,cAAc,CAAC4C,IAAI,IAAI,CAACA,IAAI,CAAC;EAC/B,CAAC;EAED,OAAO;IACL7C,WAAW;IACXE,SAAS;IACT0C,eAAe;IACfd;EACF,CAAC;AACH,CAAC;AAAC/B,EAAA,CArFID,iBAAiB;AAuFvB,eAAeA,iBAAiB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}